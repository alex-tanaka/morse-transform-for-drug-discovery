{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook III: Classifying Morse Features\n",
    "\n",
    "This notebook shows how to classify vanilla and chemically-enhanced Morse feature vectors using a tuned LighGBM. \n",
    "\n",
    "Please note that you must have generated the features before classifying them.\n",
    "\n",
    "(See the previous notebook in the series to see how to generate batches of Morse features.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMHIC9Joa3kZ"
   },
   "source": [
    "# Packages\n",
    "Import the Python packages necessary to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the working directory. This is useful to know when checking the relative file paths later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying vanilla Morse feature vectors\n",
    "\n",
    "We shall run a script `gb_tuned_sum_all_feature_classification.py` to generate the tuned LightGBM classification results for vanilla Morse feature vectors. Due to the stochasticity of the hyperparameter tuning, different runs may lead to slightly different results. You must specify various command-line arguments:\n",
    "\n",
    "Optional arguments:\n",
    "\n",
    "    -h, --help\n",
    "\n",
    "    --targets\n",
    "  \n",
    "    --dataset\n",
    "  \n",
    "    --results_prefix\n",
    "\n",
    "where \n",
    "\n",
    "* `targets` is the protein target (e.g. cxcr4), to specify multiple targets enter a space between each target name (e.g. cxcr4 ampc); \n",
    "\n",
    "* `results_prefix` specifies the filename prefix of the results files generated by the classification script; and \n",
    "\n",
    "* `dataset` refers to the feature dataset and the virtual screening dataset it was generated from e.g. dude_aligned for vanilla Morse feature vectors from the DUD-E dataset, muv_kqmolsa for KQMolSA features generated from the MUV dataset and dude_baseline_q9 for the baseline features generated from the DUD-E dataset. The precise names of these feature datasets depend on the names of the directories the features are stored in.\n",
    "\n",
    "The output of this script will be a series of results files specifying the generalisation errors of the tuned LightGBM for several metrics for each protein target.\n",
    "\n",
    "By default the script will classify Morse features with a depth of 20 and 32 pentakis dodecahedron directions. The depth `top_values` and number of directions `num_directions` can be altered by changing the following lines _in the script_:\n",
    "```\n",
    "top_values = [20]\n",
    "num_directions = 32\n",
    "```\n",
    "Note that due to how the results files are generated the depth can only take on the following values $\\{1, 3, 5, 7, 10, 13, 15, 20\\}$ and the number of directions must be an integer between 1 and 32. This all assumes that the Morse features were generated with the default parameters. If you were to generate Morse features up to depth 10 and with 5 directions, then the permissible ranges for classification would be accordingly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'num_leaves': 61, 'min_data_in_leaf': 381, 'max_depth': 99, 'lambda_l1': 8.223083836905306e-06, 'lambda_l2': 8.594689739874726e-07, 'bagging_fraction': 0.9415691853284407, 'min_sum_hessian_in_leaf': 0.9649985837003707, 'feature_fraction': 0.7949992592908648}\n",
      "Best trial final validation loss: 0.047064037129734226\n",
      "Best trial final validation ROCAUC: 0.8920401922236785\n",
      "Best trial final validation BEDROC-5: 0.7217168189451751\n",
      "Best trial final validation 1% Enrichment Factor: 25.819841269841266\n",
      "pos_weight = 85.15625 , actives = 32 , inactives =  2725\n",
      "{'device_type': 'cpu', 'num_threads': 1, 'objective': 'binary', 'scale_pos_weight': 1.0, 'num_leaves': 31, 'min_data_in_leaf': 20, 'bagging_freq': 1, 'bagging_fraction': 1.0, 'min_sum_hessian_in_leaf': 0.001, 'max_depth': 100, 'num_iterations': 100, 'learning_rate': 0.1, 'min_gain_to_split': 0, 'feature_fraction': 1.0, 'verbosity': -1}\n",
      "{'device_type': 'cpu', 'num_threads': 1, 'objective': 'binary', 'scale_pos_weight': 1.0, 'num_leaves': 61, 'min_data_in_leaf': 381, 'bagging_freq': 1, 'bagging_fraction': 0.9415691853284407, 'min_sum_hessian_in_leaf': 0.9649985837003707, 'max_depth': 99, 'num_iterations': 100, 'learning_rate': 0.1, 'min_gain_to_split': 0, 'feature_fraction': 0.7949992592908648, 'verbosity': -1, 'lambda_l1': 8.223083836905306e-06, 'lambda_l2': 8.594689739874726e-07}\n",
      "The 4-fold ROC AUC test score: 0.742474302496329\n",
      "The 4-fold EF 1% test score: 12.303571428571429\n",
      "K-FOLD CROSS VALIDATION fold_results FOR 5 FOLDS:\n",
      "\n",
      "\n",
      "roc : mean = 0.865 , std = 0.066 , lower 95% CI = 0.786 , uppper 95% CI = 0.906 , min = 0.742 , max = 0.921\n",
      "brier : mean = 0.011 , std = 0.00063 , lower 95% CI = 0.010 , uppper 95% CI = 0.012 , min = 0.010 , max = 0.012\n",
      "logl : mean = 0.051 , std = 0.008 , lower 95% CI = 0.046 , uppper 95% CI = 0.060 , min = 0.043 , max = 0.066\n",
      "bedroc_alpha5 : mean = 0.705 , std = 0.11 , lower 95% CI = 0.594 , uppper 95% CI = 0.775 , min = 0.517 , max = 0.822\n",
      "bedroc_alpha10 : mean = 0.609 , std = 0.12 , lower 95% CI = 0.501 , uppper 95% CI = 0.704 , min = 0.402 , max = 0.767\n",
      "bedroc_alpha20 : mean = 0.498 , std = 0.12 , lower 95% CI = 0.381 , uppper 95% CI = 0.588 , min = 0.308 , max = 0.683\n",
      "ef_1 : mean = 19.689 , std = 9.8 , lower 95% CI = 12.311 , uppper 95% CI = 31.554 , min = 12.304 , max = 36.911\n",
      "abs_ef_1 : mean = 0.229 , std = 0.11 , lower 95% CI = 0.143 , uppper 95% CI = 0.371 , min = 0.143 , max = 0.429\n",
      "pr_auc : mean = 0.209 , std = 0.088 , lower 95% CI = 0.137 , uppper 95% CI = 0.291 , min = 0.095 , max = 0.336\n",
      "recall : mean = 0.000 , std = 0 , lower 95% CI = nan , uppper 95% CI = nan , min = 0.000 , max = 0.000\n",
      "precision : mean = 0.000 , std = 0 , lower 95% CI = nan , uppper 95% CI = nan , min = 0.000 , max = 0.000\n",
      "accuracy : mean = 0.988 , std = 0.0012 , lower 95% CI = 0.987 , uppper 95% CI = 0.988 , min = 0.985 , max = 0.988\n"
     ]
    }
   ],
   "source": [
    "%run ../src/gb_tuned_sum_all_feature_classification.py --targets cxcr4 --results_prefix lgbm_dude_diverse_vanilla_morse --dataset dude_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>top 20</th>\n",
       "      <th>top 20 STD</th>\n",
       "      <th>top 20 low</th>\n",
       "      <th>top 20 up</th>\n",
       "      <th>top 20 min</th>\n",
       "      <th>top 20 max</th>\n",
       "      <th>top 15</th>\n",
       "      <th>top 15 STD</th>\n",
       "      <th>top 15 low</th>\n",
       "      <th>...</th>\n",
       "      <th>top 3 low</th>\n",
       "      <th>top 3 up</th>\n",
       "      <th>top 3 min</th>\n",
       "      <th>top 3 max</th>\n",
       "      <th>top 1</th>\n",
       "      <th>top 1 STD</th>\n",
       "      <th>top 1 low</th>\n",
       "      <th>top 1 up</th>\n",
       "      <th>top 1 min</th>\n",
       "      <th>top 1 max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cxcr4</td>\n",
       "      <td>0.864985</td>\n",
       "      <td>0.06585</td>\n",
       "      <td>0.786027</td>\n",
       "      <td>0.905514</td>\n",
       "      <td>0.742474</td>\n",
       "      <td>0.920888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target    top 20  top 20 STD  top 20 low  top 20 up  top 20 min  top 20 max  \\\n",
       "0  cxcr4  0.864985     0.06585    0.786027   0.905514    0.742474    0.920888   \n",
       "\n",
       "   top 15  top 15 STD  top 15 low  ...  top 3 low  top 3 up  top 3 min  \\\n",
       "0     0.0         0.0         0.0  ...        0.0       0.0        0.0   \n",
       "\n",
       "   top 3 max  top 1  top 1 STD  top 1 low  top 1 up  top 1 min  top 1 max  \n",
       "0        0.0    0.0        0.0        0.0       0.0        0.0        0.0  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the specific metric you desire\n",
    "metrics =  ['roc', 'brier', 'logl',\n",
    "            'bedroc_alpha5', 'bedroc_alpha10', 'bedroc_alpha20',\n",
    "            'ef_1', 'abs_ef_1']\n",
    "metric = metrics[0]\n",
    "\n",
    "# Select the appropriate classification run\n",
    "# (should match the classification script argument)\n",
    "dataset = 'dude_aligned' \n",
    "results_prefix = 'lgbm_dude_diverse_vanilla_morse' \n",
    "\n",
    "# Read the corresponding csv file\n",
    "results_df = pd.read_csv('../data/results/' +\n",
    "                         dataset +  '/' +\n",
    "                         '%s_%s_results.csv' %(results_prefix, metric),\n",
    "                         sep=',',\n",
    "                         index_col=0)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying chemically-enhanced Morse feature vectors\n",
    "\n",
    "We shall run a script `gb_tuned_sum_all_feature_hybrid_classification.py` to generate the tuned LightGBM classification results for chemically-enhanced Morse feature vectors. Due to the stochasticity of the hyperparameter tuning, different runs may lead to slightly different results. You must specify various command-line arguments:\n",
    "\n",
    "Optional arguments:\n",
    "\n",
    "    -h, --help\n",
    "\n",
    "    --targets\n",
    "  \n",
    "    --dataset\n",
    "\n",
    "    --baseline_dataset\n",
    "  \n",
    "    --results_prefix\n",
    "\n",
    "where \n",
    "\n",
    "* `targets` is the protein target (e.g. cxcr4), to specify multiple targets enter a space between each target name (e.g. cxcr4 ampc); \n",
    "\n",
    "* `results_prefix` specifies the filename prefix of the results files generated by the classification script; \n",
    "\n",
    "* `dataset` refers to the feature dataset and the virtual screening dataset it was generated from e.g. dude_aligned for vanilla Morse feature vectors from the DUD-E dataset, muv_kqmolsa for KQMolSA features generated from the MUV dataset. The precise names of these feature datasets depend on the names of the directories the features are stored in; and \n",
    "\n",
    "* `baseline_dataset` refers to the chemical properties dataset and the virtual screening dataset it was generated from. There are only two options: dude_baseline_q9 and muv_baseline_q9. This dataset is where the chemical properties are extracted from to supplement the Morse feature vectors with chemical information. If you selected a DUD-E feature dataset then you should also select a DUD-E baseline dataset.\n",
    "\n",
    "The output of this script will be a series of results files specifying the generalisation errors of the tuned LightGBM for several metrics for each protein target.\n",
    "\n",
    "By default the script will classify Morse features with a depth of 20 and 32 pentakis dodecahedron directions. The depth `top_values` and number of directions `num_directions` can be altered by changing the following lines _in the script_:\n",
    "```\n",
    "top_values = [20]\n",
    "num_directions = 32\n",
    "```\n",
    "Note that due to how the results files are generated the depth can only take on the following values $\\{1, 3, 5, 7, 10, 13, 15, 20\\}$ and the number of directions must be an integer between 1 and 32. This all assumes that the Morse features were generated with the default parameters. If you were to generate Morse features up to depth 10 and with 5 directions, then the permissible ranges for classification would be accordingly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'num_leaves': 17, 'min_data_in_leaf': 133, 'max_depth': 17, 'lambda_l1': 0.0002428945418263831, 'lambda_l2': 3.3002503949106756e-05, 'bagging_fraction': 0.9507748866368981, 'min_sum_hessian_in_leaf': 7.528541359893696e-07, 'feature_fraction': 0.33248784138019694}\n",
      "Best trial final validation loss: 0.008143016861063493\n",
      "Best trial final validation ROCAUC: 0.9994058540847531\n",
      "Best trial final validation BEDROC-5: 0.9971867311380682\n",
      "Best trial final validation 1% Enrichment Factor: 83.58174603174602\n",
      "{'device_type': 'cpu', 'num_threads': 1, 'objective': 'binary', 'num_leaves': 31, 'min_data_in_leaf': 20, 'bagging_freq': 1, 'bagging_fraction': 1.0, 'min_sum_hessian_in_leaf': 0.001, 'max_depth': 100, 'num_iterations': 100, 'learning_rate': 0.1, 'min_gain_to_split': 0, 'feature_fraction': 1.0, 'max_bin': 255, 'verbosity': -1}\n",
      "{'device_type': 'cpu', 'num_threads': 1, 'objective': 'binary', 'num_leaves': 17, 'min_data_in_leaf': 133, 'bagging_freq': 1, 'bagging_fraction': 0.9507748866368981, 'min_sum_hessian_in_leaf': 7.528541359893696e-07, 'max_depth': 17, 'num_iterations': 100, 'learning_rate': 0.1, 'min_gain_to_split': 0, 'feature_fraction': 0.33248784138019694, 'max_bin': 255, 'verbosity': -1, 'lambda_l1': 0.0002428945418263831, 'lambda_l2': 3.3002503949106756e-05}\n",
      "pos_weight = 85.15625 , actives = 32 , inactives =  2725\n",
      "\n",
      "\n",
      "The 4-fold ROC AUC test score: 0.9877019089574156\n",
      "The 4-fold EF 1% test score: 86.125\n",
      "K-FOLD CROSS VALIDATION fold_results FOR 5 FOLDS:\n",
      "\n",
      "\n",
      "roc : mean = 0.997 , std = 0.0047 , lower 95% CI = 0.992 , uppper 95% CI = 1.000 , min = 0.988 , max = 1.000\n",
      "brier : mean = 0.002 , std = 0.00084 , lower 95% CI = 0.001 , uppper 95% CI = 0.003 , min = 0.001 , max = 0.003\n",
      "logl : mean = 0.010 , std = 0.0049 , lower 95% CI = 0.007 , uppper 95% CI = 0.015 , min = 0.004 , max = 0.019\n",
      "bedroc_alpha5 : mean = 0.988 , std = 0.018 , lower 95% CI = 0.962 , uppper 95% CI = 0.998 , min = 0.953 , max = 1.000\n",
      "bedroc_alpha10 : mean = 0.981 , std = 0.028 , lower 95% CI = 0.940 , uppper 95% CI = 0.996 , min = 0.926 , max = 1.000\n",
      "bedroc_alpha20 : mean = 0.973 , std = 0.035 , lower 95% CI = 0.936 , uppper 95% CI = 0.992 , min = 0.903 , max = 1.000\n",
      "ef_1 : mean = 86.150 , std = 0.05 , lower 95% CI = 86.125 , uppper 95% CI = 86.225 , min = 86.125 , max = 86.250\n",
      "abs_ef_1 : mean = 1.000 , std = 0 , lower 95% CI = nan , uppper 95% CI = nan , min = 1.000 , max = 1.000\n",
      "pr_auc : mean = 0.952 , std = 0.036 , lower 95% CI = 0.914 , uppper 95% CI = 0.977 , min = 0.888 , max = 1.000\n",
      "recall : mean = 0.775 , std = 0.094 , lower 95% CI = 0.675 , uppper 95% CI = 0.850 , min = 0.625 , max = 0.875\n",
      "precision : mean = 1.000 , std = 0 , lower 95% CI = nan , uppper 95% CI = nan , min = 1.000 , max = 1.000\n",
      "accuracy : mean = 0.997 , std = 0.0011 , lower 95% CI = 0.997 , uppper 95% CI = 0.998 , min = 0.996 , max = 0.999\n"
     ]
    }
   ],
   "source": [
    "%run ../src/gb_tuned_sum_all_feature_hybrid_classification.py --targets cxcr4 --results_prefix lgbm_dude_diverse_chem_morse --dataset dude_aligned --baseline_dataset dude_baseline_q9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>top 20</th>\n",
       "      <th>top 20 STD</th>\n",
       "      <th>top 20 low</th>\n",
       "      <th>top 20 up</th>\n",
       "      <th>top 20 min</th>\n",
       "      <th>top 20 max</th>\n",
       "      <th>top 15</th>\n",
       "      <th>top 15 STD</th>\n",
       "      <th>top 15 low</th>\n",
       "      <th>...</th>\n",
       "      <th>top 3 low</th>\n",
       "      <th>top 3 up</th>\n",
       "      <th>top 3 min</th>\n",
       "      <th>top 3 max</th>\n",
       "      <th>top 1</th>\n",
       "      <th>top 1 STD</th>\n",
       "      <th>top 1 low</th>\n",
       "      <th>top 1 up</th>\n",
       "      <th>top 1 min</th>\n",
       "      <th>top 1 max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cxcr4</td>\n",
       "      <td>0.997063</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.992254</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>0.987702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target    top 20  top 20 STD  top 20 low  top 20 up  top 20 min  top 20 max  \\\n",
       "0  cxcr4  0.997063    0.004693    0.992254   0.999523    0.987702         1.0   \n",
       "\n",
       "   top 15  top 15 STD  top 15 low  ...  top 3 low  top 3 up  top 3 min  \\\n",
       "0     0.0         0.0         0.0  ...        0.0       0.0        0.0   \n",
       "\n",
       "   top 3 max  top 1  top 1 STD  top 1 low  top 1 up  top 1 min  top 1 max  \n",
       "0        0.0    0.0        0.0        0.0       0.0        0.0        0.0  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the specific metric you desire\n",
    "metrics =  ['roc', 'brier', 'logl',\n",
    "            'bedroc_alpha5', 'bedroc_alpha10', 'bedroc_alpha20',\n",
    "            'ef_1', 'abs_ef_1']\n",
    "metric = metrics[0]\n",
    "\n",
    "# Select the appropriate classification run\n",
    "# (should match the classification script argument)\n",
    "dataset = 'dude_aligned' \n",
    "results_prefix = 'lgbm_dude_diverse_chem_morse'\n",
    "\n",
    "# Read the corresponding csv file\n",
    "results_df = pd.read_csv('../data/results/' +\n",
    "                         dataset +  '/' +\n",
    "                         '%s_%s_results.csv' %(results_prefix, metric),\n",
    "                         sep=',',\n",
    "                         index_col=0)\n",
    "\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "morse_tune_lgb_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
